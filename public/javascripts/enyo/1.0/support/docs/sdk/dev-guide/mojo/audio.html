<!DOCTYPE html>
<html>
	<head>
		<title>$if(pagetitle)$$pagetitle$$endif$</title>
		<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
		<link rel="stylesheet" href="_css/chrome.css" />
		<link rel="stylesheet" href="../_css/chrome.css" />
		<link rel="stylesheet" href="../../_css/chrome.css" />
		<link rel="stylesheet" href="../../../_css/chrome.css" />
		<script src="_js/jquery-1.4.2.min.js" type="text/javascript"></script>
		<script src="../_js/jquery-1.4.2.min.js" type="text/javascript"></script>
		<script src="../../_js/jquery-1.4.2.min.js" type="text/javascript"></script>
		<script src="../../../_js/jquery-1.4.2.min.js" type="text/javascript"></script>
		<script src="_js/doc.js" type="text/javascript"></script>
		<script src="../_js/doc.js" type="text/javascript"></script>
		<script src="../../_js/doc.js" type="text/javascript"></script>
		<script src="../../../_js/doc.js" type="text/javascript"></script>
	</head>
	<body>
		<div id="content">
    
    <h1 id="audio">
      Audio
    </h1>
    <p>
      The HP webOS SDK offers two options for playing audio:
    </p>
    <ul>
      <li>
        <p>
          <strong>The webOS Streaming Music Player.</strong> If you want to play a piece of audio content (e.g. a streaming radio station, an audio book or a podcast) and don't have specialized user interface requirements, you can launch the streaming music player built into webOS. The player launches in its own card and provides basic playback controls. When finished listening to the audio, the user can toss the card away and return to your application.
        </p>
      </li>
      <li>
        <p>
          <strong>HTML 5 Audio objects.</strong> If you want to play sound effects or other audio resources that are tightly integrated with your app, or if you want to provide your own audio playback experience with a custom user interface, you can play audio using HTML 5 Audio objects.
        </p>
      </li>
    </ul>
    <p>
      Regardless of which option you choose, you can play audio from a local file on the user's device, or from a remote server. See Supported Audio Formats, below, for details on the protocols and formats webOS supports.
    </p>
    <p>
      On this page:
    </p>
    <ul>
      <li>Using the webOS Streaming Music Player
      </li>
      <li>Using HTML 5 Audio Objects
        <ul>
          <li>Adding an Audio Object
          </li>
          <li>Loading the MediaExtension Library
          </li>
          <li>Setting an Object's Audio Class
          </li>
          <li>Controlling a Media Object
            <ul>
              <li>Playing, Pausing and Seeking
              </li>
              <li>Handling Media Events
              </li>
            </ul>
          </li>
          <li>Audio Performance Tips
            <ul>
              <li>Audio Object Garbage Collection
              </li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Supported Audio Formats
      </li>
      <li>Volume Key Lock
      </li>
    </ul>
    <h2 id="using-the-webos-streaming-music-player">
      Using the webOS Streaming Music Player
    </h2>
    <p>
      To initiate playback of an audio file in the webOS Streaming Music Player app, you launch the app using the <a href="/reference/services/application-manager.html">Application Manager</a> service, providing the URL (which may be local or remote) of the file or stream you want to play.
    </p>
    <p>
      Application Manager provides two different methods for launching another application. The open method takes just a URL and uses the MIME type and/or filename extension to determine which application to launch. You may wish to use this method if you're not sure what type of resource (audio or video, for example) your URL represents and you want webOS to choose the right app for playback:
    </p>
    <blockquote>
      <pre>
<code>this.controller.serviceRequest(&quot;palm://com.palm.applicationManager&quot;,
{
  method: &quot;open&quot;,
  parameters: {
      target: &quot;http://mydomain.com/media/myfile.mp3&quot;
  }
}); 
</code>
</pre>
    </blockquote>
    <p>
      The launch method allows you to specify which application to use. As long as you're sure your URL represents an audio resource, this method gives you more control and should result in a faster launch:
    </p>
    <blockquote>
      <pre>
<code>this.controller.serviceRequest(&quot;palm://com.palm.applicationManager&quot;,
{
  method: &quot;launch&quot;,
  parameters: {
      id: &quot;com.palm.app.streamingmusicplayer&quot;,
      params: {
          target: &quot;http://mydomain.com/media/myfile.mp3&quot;
      }
  }
}); 
</code>
</pre>
    </blockquote>
    <p>
      For details on the use of Application Manager, see the Application Manager reference.
    </p>
    <p>
      <strong>Note:</strong>
    </p>
    <p>
      Video and audio playback is not currently supported in the emulator.
    </p>
    <h2 id="using-html-5-audio-objects">
      Using HTML 5 Audio Objects
    </h2>
    <p>
      <strong>Important:</strong>
    </p>
    <p>
      webOS 1.4 introduced a change in implementation of the HTML 5 Media API. Developers beginning work on new apps should use the updated API, described on this page. Developers with applications already in the App Catalog should transition to the updated API within the coming months.
    </p>
    <p>
      For playing audio within your own app, the webOS SDK supports the proposed HTML 5 Media specification. To play audio, you can create one or more Audio objects, call the methods exposed by those objects to control playback, and handle the events generated by those objects as needed.
    </p>
    <p>
      This document does not cover use of the HTML 5 Audio object in detail, but the <a href="http://www.whatwg.org/specs/web-apps/current-work/multipage/video.html">HTML 5 Media spec</a> does provide exhaustive detail, and many useful tutorials and walkthroughs may be found online.
    </p>
    <h3 id="adding-an-audio-object">
      Adding an Audio Object
    </h3>
    <p>
      An Audio object is typically added in JavaScript, using the Audio() constructor. In a Mojo Framework context, it often makes sense to do this in a scene's setup() method. For example:
    </p>
    <blockquote>
      <pre>
<code>MySceneAssistant.prototype.setup = function() {
  this.bang = new Audio();
  this.bang.src = Mojo.appPath + &quot;/audio/bang.wav&quot;;
}
</code>
</pre>
    </blockquote>
    <p>
      It's also possible to add an audio object by including the <code>&lt;audio&gt;</code> element in your HTML markup, either in your index.html file or in the view markup for a particular scene:
    </p>
    <blockquote>
      <pre>
<code>&lt;audio src=&quot;http://mydomain.com/media/myfile.mp3&quot; id=&quot;myAudioElement&quot;&gt;&lt;/audio&gt; 
</code>
</pre>
    </blockquote>
    <p>
      Note, however, that webOS does not currently support the controls attribute described in the HTML 5 proposal, so if you want to provide playback controls, you'll need to add UI elements yourself and use the methods exposed by the Audio object to control playback.
    </p>
    <h3 id="loading-the-mediaextension-library">
      Loading the MediaExtension Library
    </h3>
    <p>
      webOS adheres very closely to the HTML 5 Media spec, but there are some cases (described below) in which it's necessary to augment the specified functionality. For these cases, webOS provides the <strong>MediaExtension</strong> library.
    </p>
    <p>
      Currently, cases that require use of the MediaExtension library include:
    </p>
    <ul>
      <li>Setting an Audio or Video object's audio class
      </li>
      <li>Determining whether an Audio or Video object is pausable
      </li>
      <li>Setting a Video object's fit mode
      </li>
    </ul>
    <p>
      To use the MediaExtension library, you first need to include <strong>MojoLoader</strong> in your application by adding the following line within the <code>&lt;head&gt;</code> section of your app's <code>index.html</code> file:
    </p>
    <blockquote>
      <pre>
<code>&lt;script src=&quot;/usr/palm/frameworks/mojoloader.js&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt; 
</code>
</pre>
    </blockquote>
    <p>
      Then, generally within a scene assistant, you load the MediaExtension library and use it to instantiate a MediaExtension object for any Audio or Video object that may require one:
    </p>
    <blockquote>
      <pre>
<code>// Load the MediaExtension library
this.libs = MojoLoader.require({ name: &quot;mediaextension&quot;, version: &quot;1.0&quot;});

// If you don't already have one, get a reference to the media element, using its ID
this.mediaObj = this.controller.get(&quot;myMediaElement&quot;);

// Instantiate the MediaExtension object
this.extObj = this.libs.mediaextension.MediaExtension.getInstance(this.mediaObj);
</code>
</pre>
    </blockquote>
    <h3 id="setting-an-objects-audio-class">
      Setting an Object's Audio Class
    </h3>
    <p>
      To ensure a good user experience, webOS automatically manages some aspects of audio and video playback. For example, when a webOS device receives a phone call or triggers an audible alert, it automatically mutes, reduces the volume of, or pauses any other audio or video that may be playing.
    </p>
    <p>
      In order to do the right thing, webOS needs to know something about the nature of each media object that your application plays. You can provide webOS with the information it needs by setting an object's <strong>audio class</strong>.
    </p>
    <p>
      webOS supports a number of audio classes at the system level, but for applications there are only two classes that commonly apply: audio and video content should be assigned the media class, while application sounds (e.g. sound effects, UI cues, etc.) should be assigned the defaultapp class.
    </p>
    <p>
      webOS assumes the defaultapp audio class unless you specify otherwise, so in practice you generally only need to set the audio class for objects that should be classified as media.
    </p>
    <p>
      An Audio or Video object whose audio class is set to media behaves as follows:
    </p>
    <ul>
      <li>An object that is playing will automatically pause when a phone call begins or when another object of the media class begins playing (generally within another app).
      </li>
      <li>An Audio object that has been paused for a phone call will automatically resume playing when the call ends, but a Video object will not.
      </li>
      <li>Neither an Audio nor a Video object will automatically resume after being paused to accommodate the playback of another piece of media.
      </li>
    </ul>
    <p>
      <strong>Note:</strong>
    </p>
    <p>
      When webOS pauses or resumes playing a particular object, the object will fire a pause or play event, per the HTML 5 Media specification. Your application should listen for these events and update any playback controls your UI may provide (and perform other operations as needed). See Handling Media Events, below.
    </p>
    <p>
      To set an object's audio class, you first need to load the <strong>MediaExtension</strong> library and obtain a MediaExtension object, as described above. Once you have obtained a MediaExtension object, it's simple to set the audio class:
    </p>
    <blockquote>
      <pre>
<code>// this.extObj is a MediaExtension object associated with
// the Media object whose audio class we want to set
this.extObj.audioClass = &quot;media&quot;;
</code>
</pre>
    </blockquote>
    <h3 id="controlling-a-media-object">
      Controlling a Media Object
    </h3>
    <p>
      A detailed discussion of controlling HTML 5 Media objects is beyond the scope of this document, but this section provides a high-level introduction to controlling video objects within a webOS application. For more information, please refer to the <a href="http://www.whatwg.org/specs/web-apps/current-work/multipage/video.html">HTML 5 Media specification</a> or reference and tutorial resources available from other sources.
    </p>
    <h4 id="playing-pausing-and-seeking">
      Playing, Pausing and Seeking
    </h4>
    <p>
      Per the HTML 5 Media spec, media objects expose play() and pause() methods, and a currentTime property for seeking to a particular point in the audio. You can use these (along with the object's other methods and properties) to control playback.
    </p>
    <p>
      The following example illustrates how you might control media playback in response to button taps in your UI (assuming you are listening for taps on each button and have registered the following methods as handlers):
    </p>
    <blockquote>
      <pre>
<code>MySceneAssistant.prototype.handlePlayButtonTap = function() {
  this.mediaObj.play();
}

MySceneAssistant.prototype.handlePauseButtonTap = function() {
  this.mediaObj.pause();
}

MySceneAssistant.prototype.handleRewindButtonTap = function() {
  this.mediaObj.currentTime = 0.0;
} 
</code>
</pre>
    </blockquote>
    <h4 id="determining-whether-a-media-object-is-pausable">
      Determining Whether a Media Object is Pausable
    </h4>
    <p>
      Some media streams that use the RTSP protocol are not pausable. You may need to adjust your application's playback UI or logic in this case, so webOS provides a mechanism for checking to see whether an object is pausable.
    </p>
    <p>
      You first need to load the <strong>MediaExtension</strong> library and obtain a MediaExtension object, as described above. Once you have obtained a MediaExtension object, you can check for pausability as shown here:
    </p>
    <blockquote>
      <pre>
<code>// this.extObj is a MediaExtension object associated with
// the Media object whose pausability we want to check
if (this.extObj.pausable) {
  // Adjust UI and app logic accordingly...
} 
</code>
</pre>
    </blockquote>
    <h4 id="handling-media-events">
      Handling Media Events
    </h4>
    <p>
      HTML 5 Media objects fire a variety of events to indicate state changes. You can listen for these events and respond as appropriate within your application.
    </p>
    <p>
      As noted above, under certain circumstances webOS may automatically pause and resume playback of objects whose audio class you have set to media. When this occurs, the affected object will fire a pause or play event, which you should use to trigger UI updates and any other operations your app may need to perform.
    </p>
    <p>
      The following example illustrates how to listen for and respond to these events:
    </p>
    <blockquote>
      <pre>
<code>MySceneAssistant.prototype.setup = function() {
  // Load the MediaExtension library, required to set audio class
  this.libs = MojoLoader.require({ name: &quot;mediaextension&quot;, version: &quot;1.0&quot;});

  // Get a reference to the media element, using its ID
  this.mediaObj = this.controller.get(&quot;myMediaElement&quot;);

  // Get the MediaExtension object and set the audio class
  this.extObj = this.libs.mediaextension.MediaExtension.getInstance(this.mediaObj);
  this.extObj.audioClass = &quot;media&quot;;

  // Listen for pause and play events
  this.mediaObj.addEventListener(&quot;pause&quot;, this.handlePause.bind(this), true);
  this.mediaObj.addEventListener(&quot;play&quot;, this.handlePlay.bind(this), true);
}

MySceneAssistant.prototype.handlePause = function(evt) {
  Mojo.Log.info(&quot;received pause event&quot;);
  // Update UI, etc.
}
MySceneAssistant.prototype.handlePlay = function(evt) {
  Mojo.Log.info(&quot;received play event&quot;);
  // Update UI, etc.
} 
</code>
</pre>
    </blockquote>
    <h3 id="audio-performance-tips">
      Audio Performance Tips
    </h3>
    <p>
      If your app plays multiple short sounds (as effects or UI cues, for example), the following tips will help to maximize performance.
    </p>
    <ul>
      <li>Create a separate Audio object for each sound you will play.
      </li>
      <li>Pre-load each Audio object upon creation using the object's load() method, so that it doesn't need to be loaded implicitly when first played.
      </li>
      <li>Use the WAV format, sampled at 44100 Hz (16-bit only), for your sounds.
      </li>
      <li>If possible, avoid playing multiple sounds simultaneously.
      </li>
    </ul>
    <h4 id="audio-object-garbage-collection">
      Audio Object Garbage Collection
    </h4>
    <p>
      Be aware that holding references to many Audio objects simultaneously can affect your application and system performance due to memory constraints. At some point audio may stop functioning requiring a device reset.
    </p>
    <p>
      When you allocate a new Audio object in your app, i.e., by using <code>new Audio()</code>, a JavaScript object will be returned which will be garbage collected when you no longer have any references to it in your code. Therefore a best practice is to make sure that you do not hold references to unneeded Audio objects.
    </p>
    <p>
      Also keep in mind that when you add an Audio object by including an <code>&lt;audio&gt;</code> element in your HTML markup garbage collection will occur when the scene is popped. For example when using this form:
    </p>
    <blockquote>
      <pre>
<code>&lt;audio src=&quot;http://mydomain.com/media/myfile.mp3&quot; id=&quot;myAudioElement&quot;&gt;&lt;/audio&gt;
</code>
</pre>
    </blockquote>
    <p>
      the Audio object associated with this HTML element will be garbage collected when the corresponding scene is popped.
    </p>
    <h2 id="supported-audio-formats">
      Supported Audio Formats
    </h2>
    <p>
      This section lists the supported audio formats and recommended streaming protocols.
    </p>
    <h3 id="supported-formats">
      Supported Formats
    </h3>
    <p>
      The following are the supported audio formats:
    </p>
    <ul>
      <li>AAC (LC-AAC)
      </li>
      <li>AAC+ (HE-AAC)
      </li>
      <li>eAAC+ (HEv2-AAC)
      </li>
      <li>AMR (NB-AMR)
      </li>
      <li>MP3
      </li>
      <li>QCELP
      </li>
      <li>WAV (ADPCM, LPCM, aLaw, uLaw), 16-bit
      </li>
    </ul>
    <h3 id="streaming">
      Streaming
    </h3>
    <p>
      The following table lists the recommended encoding settings for streaming.
    </p>
    <table border="1" cellspacing="2" cellpadding="2" style="text-align: left; width: 100%">
      <tbody>
        <tr>
          <th>
            Protocol
          </th>
          <th>
            Bandwidth
          </th>
          <th>
            Recommended
          </th>
          <th>
            Supported
          </th>
        </tr>
        <tr>
          <td rowspan="2" style="vertical-align: top">
            HTTP progressive download
          </td>
          <td>
            High
          </td>
          <td>
            64 Kbps, AAC+, 44 KHz, stereo.
          </td>
          <td>
            All local formats are supported.
          </td>
        </tr>
        <tr>
          <td>
            Low
          </td>
          <td>
            24 Kbps, eAAC+, 44 KHz, stereo.
          </td>
          <td>
            All local formats are supported.
          </td>
        </tr>
        <tr>
          <td>
            Real time streaming protocol (RTSP)
          </td>
          <td>
            Low
          </td>
          <td>
            24 Kbps, eAAC+, 44 KHz, stereo.
          </td>
          <td>
            AAC or AMR
          </td>
        </tr>
        <tr>
          <td rowspan="2" style="vertical-align: top">
            SHOUTcast and Icecast
          </td>
          <td>
            High
          </td>
          <td>
            64 Kbps, AAC+, 44 KHz, stereo.
          </td>
          <td>
            AAC or MP3
          </td>
        </tr>
        <tr>
          <td>
            Low
          </td>
          <td>
            24 Kbps, eAAC+, 44 KHz, stereo.
          </td>
          <td>
            AAC or MP3
          </td>
        </tr>
      </tbody>
    </table>
    <h3 id="volume-key-lock">
      Volume Key Lock
    </h3>
    <p>
      The <code>lockVolumeKeys</code> method of the audio media player service allows the device's volume keys to adjust the media volume. Call this when your application requires the volume keys to adjust media volume rather than ringtone volume.
    </p>
    <p>
      The typical use case would be when a media-based application is active, but media is not currently playing. In this case, the user expects volume keys to control the media volume setting. However, by default, if media is not playing, the volume keys still control the ringer volume.
    </p>
    <p>
      Here's an example from the Music Player app:
    </p>
    <blockquote>
      <pre>
<code>markAppForeground: function(callback) {
  var parameters = {};
  parameters.subscribe = true;
  parameters.foregroundApp = true;
  return new Mojo.Service.Request(
      &quot;palm://com.palm.audio/media&quot;,
      {
          method: 'lockVolumeKeys',
          onSuccess: callback,
          parameters: parameters
      }
  );
} 
</code>
</pre>
    </blockquote>
    <p>
      This allows the user to change the volume level even though a song isn't currently playing.
    </p>
    <p>
      See also:
    </p>
    <ul>
      <li>
        <a href="/reference/services/key-service.html">Key Service</a>
      </li>
    </ul>
		</div>
	</body>
</html>